## Легенда (полная) Последний проект

## Короткая версия

**Команда:**

- **TeamLead & Архитектор:** Общая архитектура, ключевые решения, координация.
- **PM:** Управление задачами, сроками, коммуникация с заказчиком.
- **Embedded-инженер:** Работа с CAN-шиной, прошивки MCU, шлюз на Jetson (взаимодействие с бортом).
- **5 Backend-разработчиков (Go):** Разработка сервисов бэкенда. Я был одним из них, пришел Junior, к концу проекта - уверенный Mid.
- **DevOps:** Инфраструктура (Docker, k8s?), CI/CD, мониторинг (Prometheus/Grafana), управление MinIO/Kafka.

**Архитектура системы (Общая картина):**
Система состояла из нескольких микросервисов (Go):

1.  **API Gateway (gRPC/REST):** Прием команд от UI/внешних систем.
2.  **Сервис управления заданиями (Jobs Service):** Хранение заданий на обновление (PostgreSQL), их жизненный цикл (создание, планирование, статусы).
3.  **Планировщик (Scheduler):** Отслеживание времени выполнения заданий, запуск обновлений по расписанию/немедленно.
4.  **Диспетчер (Dispatcher):** Получение готовых к выполнению заданий от Планировщика, взаимодействие с устройствами через MQTT.
5.  **Сервис обработки событий (Events Service):** Прием статусов обновлений от устройств (через MQTT/Kafka), обновление статусов заданий, запись логов/метрик.
6.  **Сервис Roll-out:** Управление стратегией обновления партиями (по ТЗ от архитектора).
7.  **Хранилище прошивок (MinIO):** S3-совместимое хранилище для бинарников прошивок.
8.  **MQTT-брокер:** Шина для команд устройству и приема статусов.
9.  **UI:** Панель управления для операторов.

![Service Architecture](/assets/kamaz-arch.png)

**Процесс обновления:**

1.  Оператор создает задание в UI (устройство, версия прошивки, время запуска).
2.  `API Gateway` передает задание в `Сервис управления заданиями`.
3.  `Планировщик` видит задание с временем запуска. Когда время наступает, он помечает задание "готово к выполнению".
4.  `Диспетчер` находит готовые задания. Для каждого:
    - Формирует MQTT-команду на обновление для конкретного устройства/шлюза.
    - Отправляет команду через MQTT-брокер.
5.  Устройство/Шлюз получает команду:
    - Загружает указанную прошивку с MinIO.
    - Обновляет себя, проходя этапы (`init`, `downloading`, `flashing`, `rebooting`).
    - Отправляет статусы обратно через MQTT (`in_progress`, `downloading`, `done`, `error`).
6.  `Сервис обработки событий` подписан на MQTT/Kafka, получает статусы:
    - Обновляет статус задания и лог в `Сервисе управления заданиями` (PostgreSQL).
    - Отправляет метрики в Prometheus (через встроенный клиент).
    - Если реализован Roll-out, уведомляет `Сервис Roll-out` о статусе для управления очередностью партий.
7.  UI отображает актуальные статусы заданий и устройств.

"В 2024-2025 годах я работал в команде бэкенд-разработчиков на Go в проекте МГТУ им. Баумана для КАМАЗа. Мы создавали систему централизованных OTA-обновлений для бортовой электроники самосвалов – микроконтроллеров (STM32, ESP32) и вычислительных модулей (Jetson). Задача была сложной: обеспечить надежную доставку прошивок в условиях карьеров с плохой связью и гарантировать безопасность процесса. Обновления могли быть плановыми, аварийными или по запросу.

**Моя роль и рост:**
Я пришел Junior разработчиком. Под руководством TeamLead и опытных мидлов/сеньоров мой вклад и ответственность росли:

1.  **Начало:** Разрабатывал базовые CRUD-операции для заданий на обновление в основном Сервисе управления (Go, PostgreSQL, gRPC). Писал простые эндпоинты по готовым спецификациям.
2.  **Рост:** Постепенно брал более сложные задачи: интеграцию Сервиса заданий с очередью Kafka (отправка событий о новых заданиях), написание части Планировщика (обработка событий из Kafka, управление внутренней очередью на горутинах и каналах), интеграцию Диспетчера с MQTT-брокером (отправка команд на устройства).
3.  **К концу проекта (Mid):** Отвечал за ключевые части Сервиса обработки событий: написал консьюмера Kafka, который принимал статусы обновлений (`downloading`, `done`, `error`) от устройств, парсил их, обновлял состояние заданий в БД и метрики Prometheus. Также участвовал в реализации логики уведомления для сервиса Roll-out при групповых обновлениях.

Сложная задача
Гарантированная доставка событий в Kafka без потерь при сбоях
Контекст:
Ты писал продюсер Kafka в Сервисе заданий: при создании или изменении задания нужно было отправить событие в Kafka (например, job.created, job.status.changed). Но был риск потери событий в случае сбоя между записью в PostgreSQL и отправкой в Kafka.

Проблема:

Если сначала сохранить в БД, потом отправить в Kafka — при краше после сохранения, но до отправки → событие теряется.

Если наоборот — сначала отправить в Kafka, потом в БД — тогда клиент Kafka может получить событие, а данных в БД ещё нет.

Что ты сделал:

Вместе с TeamLead реализовали "outbox pattern":

Сначала записывали событие в отдельную таблицу event_outbox внутри одной транзакции с заданием.

Отдельный воркер (goroutine) периодически читал event_outbox, публиковал событие в Kafka и помечал его как "отправлен".

Добавил retry-механику и дед-латтер логику (если событие не удается отправить N раз — уходит в отдельную таблицу event_dead_letter для расследования).

Метрики: outbox_pending_total, outbox_errors_total.

Результат:

Потери событий между БД и Kafka полностью исключены.

Сервис стал гораздо надежнее при перезапусках или кратковременных сбоях Kafka.

Зачем всё это?
Если бы ты сразу пытался отправить в Kafka (минуя event_outbox), то: - Kafka недоступна → событие потеряно. - Или: отправил в Kafka, а потом не смог записать в PostgreSQL → рассинхрон.

А с event_outbox у тебя есть: - атомарность — всё важное сохраняется в БД. - гарантия доставки — даже если Kafka лежит, событие не потеряно. - retry — временные сбои не страшны. - контроль — если что-то не отправляется долго, ты это знаешь.

Почему круто:
Паттерн "outbox" — очень уместен в реальных прод-системах.
Показано понимание проблемы атомарности между БД и брокером.
Имеется архитектурное мышление — даже если это было по совету тимлида.

================================
Факап (пример №3): Проблема с конкурентной модификацией заданий
Что произошло:

Устройства слали статусы одновременно (например, 30 устройств из одной группы).

В Event-сервисе шёл gRPC вызов в Job-сервис: обновить статус задания.

Ты не предусмотрел блокировку на уровне БД или optimistic locking.

В итоге:

При одновременном обновлении одного и того же задания, происходил race condition:

Один статус "затирал" другой (например, in_progress пришёл после done).

В БД оказывался некорректный финальный статус.

Как решили:

Вместе с более опытным коллегой внедрили optimistic locking:

В таблицу заданий добавили поле version INT.

Обновление шло с условием WHERE id = ? AND version = ?.

Если обновление не произошло (0 строк) — повторить попытку (до N раз).

Также валидацию: нельзя обновить done → in_progress.

Уроки:

Работа с конкурентными обновлениями — тонкая вещь.

Лучше превентивно закладываться на race conditions, особенно в системах с высоким параллелизмом.

В Go нет глобального mutex — нужно проектировать защиту на уровне БД.

**Интересная и сложная задача (Обработка статусов в реальном времени):**
Одной из самых интересных и сложных для меня задач на уровне мидла стала **надежная обработка потока статусов от устройств в Сервисе событий**. Сложность была в нескольких аспектах:

- **Асинхронность и масштаб:** Устройства присылали статусы асинхронно, иногда сотнями. Нужно было потреблять их из Kafka без потерь и задержек, используя Consumer Groups.
- **Сопоставление статуса с заданием:** Устройство присылает только свой VIN и ID прошивки. Найти _активное_ задание для этого устройства и прошивки в PostgreSQL требовало оптимизированных запросов и кэширования.
- **Идемпотентность и надежность:** Связь ненадежна – устройство могло прислать `downloading` дважды, или сервис мог упасть _после_ обработки статуса, но _до_ сохранения в БД. Нужно было гарантировать, что итоговый статус (`done`/`error`) запишется ровно один раз, даже при перезапусках. Мы добились этого, коммитя оффсет в Kafka только _после_ успешной записи в PostgreSQL и используя уникальные ID сообщений для идемпотентной обработки.

Работая над этим под руководством сеньора, я глубоко разобрался в работе Kafka Consumer Groups в Go, паттернах идемпотентной обработки и важности гарантированной записи состояния в распределенных системах. Это дало огромный скачок в понимании backend-разработки для IoT.

**Факап, решение и уроки (Deadlock в обработчике статусов):**
Был и поучительный факап, который стал ценным уроком. В коде обработчика статусов **возник deadlock**, тормозивший весь сервис.

- **Что случилось:** При обработке статуса (например, `done`) код последовательно:

  1.  Вызывал gRPC API Сервиса заданий для обновления статуса (это сетевой вызов, мог быть медленным).
  2.  Отправлял событие в Kafka для Roll-out.
  3.  Обновлял метрики Prometheus (`update_status_total` и др.).
      Для защиты _общих_ структур метрик (что было избыточно) я использовал **мьютекс**. И вот ошибка: я **захватывал мьютекс ДО сетевого вызова**.

- **Почему факап:** При высокой нагрузке горутина захватывала мьютекс и шла делать долгий сетевой вызов. Все остальные горутины, обрабатывавшие другие статусы, вставали в очередь на этот же мьютекс. Сервис "вешался", накапливая лаг. Сработал алерт Prometheus.

- **Как решали:** Команда оперативно среагировала (спасибо мониторингу!).
  1.  **Диагностика:** Сеньор помог снять pprof-профиль – сразу увидели гору ждущих горутин и одну, держащую мьютекс в ожидании сети. Логи подтвердили таймауты вызовов.
  2.  **Хотфикс:** Под руководством быстро вынесли обновление метрик Prometheus _вне_ критической секции. Сам клиент Prometheus потокобезопасен для основных операций! Использовали `atomic` для счетчиков, где нужно было.
  3.  **Постоянное решение:** Убрали глобальный мьютекс для метрик. Переписали логику обработчика: быстрые операции (парсинг, валидация, атомарное обновление локальных счетчиков) – делаем до сетевых вызовов. Сетевые вызовы – делаем _без_ блокировки других горутин. Написали нагрузочный тест.

# ===

# ===

# ===

**OTA-обновления для самосвалов КАМАЗ: Мой опыт (2024-2025)**

**Контекст проекта:**
В лаборатории СМ МГТУ им. Баумана разрабатывалась система централизованных OTA-обновлений для бортовой электроники самосвалов КАМАЗ. Задача: обеспечить надежное и контролируемое обновление прошивок на разнородных устройствах (STM32, Jetson, ESP32) в условиях нестабильной связи (карьеры, удаленные локации). Обновления инициировались централизованно: планово, по запросу или аварийно (например, при критическом баге).

**Команда:**

- **TeamLead & Архитектор:** Общая архитектура, ключевые решения, координация.
- **PM:** Управление задачами, сроками, коммуникация с заказчиком.
- **Embedded-инженер:** Работа с CAN-шиной, прошивки MCU, шлюз на Jetson (взаимодействие с бортом).
- **5 Backend-разработчиков (Go):** Разработка сервисов бэкенда. Я был одним из них, пришел Junior, к концу проекта - уверенный Mid.
- **DevOps:** Инфраструктура (Docker, k8s?), CI/CD, мониторинг (Prometheus/Grafana), управление MinIO/Kafka.

**Архитектура системы (Общая картина):**
Система состояла из нескольких микросервисов (Go):

1.  **API Gateway (gRPC/REST):** Прием команд от UI/внешних систем.
2.  **Сервис управления заданиями (Jobs Service):** Хранение заданий на обновление (PostgreSQL), их жизненный цикл (создание, планирование, статусы).
3.  **Планировщик (Scheduler):** Отслеживание времени выполнения заданий, запуск обновлений по расписанию/немедленно.
4.  **Диспетчер (Dispatcher):** Получение готовых к выполнению заданий от Планировщика, взаимодействие с устройствами через MQTT.
5.  **Сервис обработки событий (Events Service):** Прием статусов обновлений от устройств (через MQTT/Kafka), обновление статусов заданий, запись логов/метрик.
6.  **Сервис Roll-out:** Управление стратегией обновления партиями (по ТЗ от архитектора).
7.  **Хранилище прошивок (MinIO):** S3-совместимое хранилище для бинарников прошивок.
8.  **MQTT-брокер:** Шина для команд устройству и приема статусов.
9.  **UI:** Панель управления для операторов.

![Service Architecture](/assets/kamaz-arch.png)

**Процесс обновления:**

1.  Оператор создает задание в UI (устройство, версия прошивки, время запуска).
2.  `API Gateway` передает задание в `Сервис управления заданиями`.
3.  `Планировщик` видит задание с временем запуска. Когда время наступает, он помечает задание "готово к выполнению".
4.  `Диспетчер` находит готовые задания. Для каждого:
    - Формирует MQTT-команду на обновление для конкретного устройства/шлюза.
    - Отправляет команду через MQTT-брокер.
5.  Устройство/Шлюз получает команду:
    - Загружает указанную прошивку с MinIO.
    - Обновляет себя, проходя этапы (`init`, `downloading`, `flashing`, `rebooting`).
    - Отправляет статусы обратно через MQTT (`in_progress`, `downloading`, `done`, `error`).
6.  `Сервис обработки событий` подписан на MQTT/Kafka, получает статусы:
    - Обновляет статус задания и лог в `Сервисе управления заданиями` (PostgreSQL).
    - Отправляет метрики в Prometheus (через встроенный клиент).
    - Если реализован Roll-out, уведомляет `Сервис Roll-out` о статусе для управления очередностью партий.
7.  UI отображает актуальные статусы заданий и устройств.

**Мое конкретное участие и вклад (Junior -> Mid Go разработчик):**

Я работал в команде бэкенд-разработчиков под руководством TeamLead и более опытных мидлов/сеньоров. Мои задачи и зона ответственности развивались по мере роста:

1.  **Разработка и поддержка Сервиса управления заданиями (начало, Junior):**

    - **Задачи:** Написание CRUD-операций для заданий в PostgreSQL (под руководством). Реализация простых эндпоинтов gRPC (GetJobByID, ListJobs) по готовым прото-контрактам.
    - **Технологии:** Go, PostgreSQL (драйвер `pgx`/`sqlx`), gRPC (`protobuf`, `grpc-go`).
    - **Уровень:** Исполнение четких ТЗ, код-ревью у сеньоров, изучение best practices.

2.  **Интеграция с очередью (Kafka/Redis) и Планировщиком (рост до Mid):**

    - **Задачи:**
      - Реализация продюсера в Сервисе заданий: При создании/изменении задания отправлять событие в Kafka/Redis (по готовой схеме события).
      - Реализация консьюмера в Планировщике: Чтение событий из Kafka/Redis, фильтрация событий о "готовности" задания, передача готовых заданий во внутреннюю очередь Планировщика (канал Go).
      - Помощь в поддержке логики Планировщика: Реализация worker'ов на горутинах, обрабатывающих задания из внутренней очереди и передающих их Диспетчеру (через вызов его API или общую шину).
    - **Технологии:** Go, Kafka (`sarama` клиент) / Redis (`go-redis`), горутины, каналы.
    - **Уровень:** Работа с асинхронными паттернами, понимание работы брокеров сообщений, решение задач средней сложности под умеренным контролем.

3.  **Работа с Диспетчером и MQTT:**

    - **Задачи:**
      - Интеграция Диспетчера с MQTT-брокером (например, EMQX): Настройка подключения, реализация публикации команд обновления в нужные MQTT-топики (`kamaz/vin123/update/command`) по шаблону от embedded-инженера.
      - Обработка ошибок отправки (таймауты, ошибки сети), реализация простого retry механизма (по ТЗ).
    - **Технологии:** Go, MQTT (клиент типа `paho.mqtt.golang`).
    - **Уровень:** Работа с внешними протоколами, реализация сетевой логики.

4.  **Сервис обработки событий (статусы) и Мониторинг:**

    - **Задачи:**
      - Реализация консьюмера MQTT/Kafka в Сервисе событий для приема статусов от устройств (`kamaz/+/update/status`).
      - Парсинг входящих статусов (JSON), валидация.
      - Обновление статуса соответствующего задания в Сервисе управления заданиями через его API.
      - Инструментирование кода: Добавление метрик Prometheus (счетчики `update_requests_total`, `update_errors_total` по типам ошибок, гистограммы `download_duration_seconds`) по согласованным метрикам от DevOps/TeamLead.
    - **Технологии:** Go, MQTT/Kafka, Prometheus client (`prometheus/client_golang`), gRPC (вызовы других сервисов).
    - **Уровень:** Интеграция между сервисами, работа с метриками, обработка событий в реальном времени.

5.  **Участие в реализации Roll-out (под руководством):**
    - **Задачи:** Не разрабатывал стратегию, но реализовывал ее часть по ТЗ:
      - В Сервисе заданий: Добавление поля `batch_group` к заданию при создании массового обновления.
      - В Сервисе событий: При получении статуса `done`/`error` от устройства, уведомление `Сервиса Roll-out` (через Kafka/API) о результате в конкретной `batch_group`.
      - В Сервисе Roll-out (помощь): Реализация логики ожидания успеха N% устройств в группе перед отправкой сигнала `Планировщику` на запуск следующей партии (через событие в Kafka/Redis).
    - **Уровень:** Работа над важным, но четко поставленным кусочком функционала в рамках общей стратегии.

**Что я освоил/укрепил:**

- **Go:** От базового синтаксиса до работы с горутинами, каналами, сетевыми запросами (gRPC, HTTP), БД (PostgreSQL), брокерами (Kafka, Redis, MQTT), метриками (Prometheus).
- **Архитектура:** Понимание микросервисной архитектуры, взаимодействие сервисов через gRPC и очереди (Kafka/Redis).
- **Базы данных:** Работа с PostgreSQL (структуры, запросы, миграции - возможно с инструментами вроде `golang-migrate`).
- **Инфраструктурные компоненты:** Практический опыт работы с Kafka, Redis, MQTT, MinIO, Docker.
- **Процессы:** Работа в команде, Git, CI/CD (наблюдение/использование), код-ревью, работа по ТЗ и спецификациям.

**Итог моего участия:**
Я был **исполнителем** в команде backend-разработчиков, ответственным за реализацию и поддержку **конкретных модулей и интеграций** в рамках общей архитектуры, спроектированной TeamLead и архитектором. Мои задачи были четко поставлены, а решения часто проходили ревью у более опытных коллег. Я начинал с простых CRUD и к концу проекта уверенно работал над задачами средней сложности, связанными с асинхронной обработкой событий, сетевым взаимодействием и интеграцией компонентов системы. Проект стал отличной школой для перехода от Junior к Mid-уровню в Go-разработке, дал глубокое понимание backend-разработки для IoT-систем в промышленном контексте.

=====================================

Задачи и факапы

**1. Какие сложные/интересные задачи приходилось решать? (Обсуждение с "Боссом" - TeamLead/Сеньором)**

- **Контекст:** На собеседовании этот вопрос задают, чтобы понять ваш уровень сложности, подход к решению проблем и чему вы научились. Не нужно выдумывать гениальность, говорите о том, что было _для вас_ сложным и интересным на вашем уровне.
- **Подход:** Выберите 1-2 задачи, которые соответствуют вашему уровню (Mid), связаны с ключевыми аспектами проекта (IoT, OTA, микросервисы) и где вы внесли ощутимый вклад.

**Пример ответа (с элементами обсуждения):**

"Босс, помнишь, в проекте OTA для КАМАЗ было несколько задач, которые для меня, как начинающего/растущего разработчика, были и сложными, и очень интересными, потому что заставляли глубоко разбираться в технологиях и особенностях предметной области:

1.  **Реализация надежной обработки статусов от устройств в реальном времени (Сервис событий):**

    - **Сложность (Для меня тогда):** Устройства присылают статусы (`downloading`, `flashing`, `error`) асинхронно через MQTT. Нужно было:
      - Обеспечить **устойчивое потребление** этих сообщений из Kafka (куда их проксировал MQTT-брокер) даже при пиковых нагрузках или временных сбоях сервиса. (Использовали Consumer Groups в Kafka).
      - **Корректно сопоставить** входящее сообщение статуса с конкретным _заданием_ в системе. Устройство знает только свой VIN и ID прошивки, а задание хранится в PostgreSQL. Требовался эффективный и надежный механизм поиска "активного" задания для данного устройства и данной прошивки.
      - **Обработать возможные "дубли" или "потерянные" статусы.** Связь ненадежна, устройство могло отправить `downloading` несколько раз. Нужно было обновлять статус задания идемпотентно.
      - **Гарантировать запись** итогового статуса (`done`/`error`) даже в случае перезапуска сервиса _после_ получения статуса, но _до_ его сохранения в БД. (Использовали механизм коммитов оффсетов в Kafka _после_ успешной записи в PostgreSQL).
    - **Интерес:** Это была моя первая серьезная задача, связанная с **асинхронной обработкой событий в реальном времени** и **обеспечением надежности данных** в распределенной системе. Потребовалось глубоко понять, как работают консьюмеры Kafka в Go, как проектировать идемпотентные обработчики, и как управлять транзакционностью между БД и очередью (хотя бы на уровне логики приложения). Работал под твоим руководством, ты помогал с проектированием ключевых аспектов и код-ревью.
    - **Итог:** Реализовал консьюмер, который устойчиво обрабатывал поток событий, корректно обновлял статусы заданий и метрики в Prometheus, обеспечив надежную обратную связь о процессе обновления.

2.  **Интеграция Диспетчера с MQTT и реализация Retry-логики:**
    - **Сложность (Для меня тогда):** Отправка команд обновления на устройства – критичное действие. Нужно было:
      - Надежно интегрироваться с MQTT-брокером (EMQX) через Go-клиент (`Paho`). Разобраться с QoS (выбрали QoS 1 - "доставлен хотя бы раз"), keepalive, обработкой разрывов соединения.
      - **Придумать и реализовать стратегию повторных попыток (Retry)** при неудачной отправке команды (сеть, временная недоступность брокера/устройства). Требовалось избежать лавинообразного роста повторных отправок. (Реализовали exponential backoff с jitter и ограничением макс. попыток).
      - **Разграничить типы ошибок:** Некоторые ошибки (неверный топик) не требовали retry, а были признаком бага в системе. Другие (таймаут сети) – требовали.
      - **Логировать и метрировать:** Четко фиксировать причины ошибок отправки для отладки и мониторинга (метрика `dispatcher_mqtt_errors` с лейблом `reason`).
    - **Интерес:** Погружение в **протокол MQTT** и практические аспекты его использования в промышленном IoT было очень полезным. Задача заставила серьезно задуматься об **устойчивости сетевых взаимодействий** и способах борьбы с неизбежными временными сбоями в условиях плохой связи карьеров. Получил ценный опыт проектирования отказоустойчивых механизмов.
    - **Итог:** Диспетчер стал надежно отправлять команды, а система получила понятную логику повторных попыток и инструменты для мониторинга проблем с доставкой команд."

**Почему это хорошо:** Показаны конкретные технические сложности на уровне мидла (работа с очередями, сетевое взаимодействие, надежность), объяснен _почему_ это было сложно/интересно _для вас_, четко обозначена ваша зона ответственности и результат. Упоминается руководство сеньора – это реалистично.

---

**2. Какой у тебя мог быть факап на работе? Как его решили? (Обсуждение с "Боссом" - TeamLead/Сеньором)**

- **Контекст:** Вопрос проверяет честность, способность признавать ошибки, извлекать уроки и, главное, **умение их исправлять**. Факап должен быть _реалистичным_ для вашего уровня, _не катастрофичным_ (не "уронил прод на сутки"), и должен демонстрировать процесс решения и командную работу.
- **Подход:** Выберите факап, связанный с технической ошибкой в коде или конфигурации, который _был обнаружен и исправлен до серьезных последствий в продакшене_ (или последствия были минимальны). Акцент на **обнаружении, анализе и исправлении**.

**Пример ответа (с элементами обсуждения):**

"Босс, один из поучительных моментов, который хорошо запомнился – это инцидент, связанный с **блокировками (deadlock) в коде Сервиса событий** при обновлении статусов заданий. Это был хороший урок по асинхронности в Go.

- **Факап:**
  - В коде обработчика статусов (в Сервисе событий) при получении статуса `done` или `error` нужно было:
    1.  Обновить статус самого задания в PostgreSQL (через вызов API Сервиса заданий).
    2.  Отправить событие в Kafka для Сервиса Roll-out (если задание было частью партии).
    3.  Обновить несколько метрик Prometheus (`update_status_total`, `last_update_time` и т.д.).
  - Я реализовал это _последовательно_ в одной горутине, но с использованием **мьютекса для защиты общих структур с метриками** (которые обновлялись из многих горутин). При этом вызов API к Сервису заданий мог иногда занимать значительное время (сетевые лаги или нагрузка).
  - **Что произошло:** В периоды высокой нагрузки, когда много статусов приходило одновременно, горутина обработчика захватывала мьютекс метрик _перед_ долгим сетевым вызовом. Это блокировало _все другие_ горутины обработчика, которые тоже пытались обновить метрики. Возник **deadlock** – горутины ждали мьютекс, который удерживался горутиной, сама ждавшей ответа от сети. Сервис начинал "тормозить", очередь статусов росла, алертил Prometheus по `event_processing_lag`.
- **Обнаружение:**
  - Ты обратил внимание на алерт от Prometheus о высокой задержке обработки событий и резком падении rate метрик.
  - Посмотрели логи – увидели таймауты на вызовах к Сервису заданий.
  - Сняли **pprof** (профиль горутин и мьютексов) с проблемного инстанса Сервиса событий – и сразу увидели кучу заблокированных горутин на одном мьютексе и горутину, которая его удерживает и висит на HTTP-вызове.
- **Решение (Как исправляли):**
  - **Срочно:** Ты помог быстро написать и прокатить хотфикс: **вынес обновление метрик Prometheus _вне_ секции, защищенной мьютексом, и сделал его атомарным** (использовали `atomic` операции для простых счетчиков и `prometheus.GaugeFunc` для `last_update_time`). Это сразу разблокировало обработчики.
  - **Правильно:** После тушения пожара, мы вместе проанализировали код:
    - Убрали **глобальный мьютекс** для метрик. Prometheus клиент и так потокобезопасен для большинства операций инкремента, если использовать правильные методы (`Inc()`, `Add()`). Для сложных обновлений использовали более тонкие примитивы или вынесли логику.
    - **Реструктурировали логику обработчика:** Сделали сетевые вызовы (к Сервису заданий и Kafka) _асинхронно_ или, как минимум, _после_ выполнения быстрых локальных операций (парсинга, валидации, обновления локальных атомарных счетчиков).
    - **Написали нагрузочный тест,** симулирующий поток статусов, чтобы отловить подобные проблемы заранее.
- **Уроки:**
  - **Глубокое понимание примитивов синхронизации:** Deadlock – коварная вещь. Теперь я всегда дважды думаю, где и как использовать мьютексы, особенно в сочетании с сетевыми вызовами.
  - **Профилирование (pprof) – мощный инструмент:** Научился его использовать для диагностики проблем с горутинами и блокировками.
  - **Атомарные операции и потокобезопасность клиентов:** Важно понимать, какие библиотеки требуют синхронизации, а какие – нет.
  - **Приоритетность операций:** Не блокировать быстрые операции (обновление метрик) из-за медленных (сеть). Разделять их.
  - **Ценность мониторинга и алертинга:** Без Prometheus и нашего дашборда мы бы заметили проблему гораздо позже.
  - **Командная работа:** Твоя оперативная помощь в анализе и горячем исправлении была неоценима. Это показало важность код-ревью и совместного разбора сложных инцидентов."

**Почему это хорошо:**

1.  **Реалистичный факап:** Техническая ошибка уровня мидла (синхронизация в Go + сетевые вызовы).
2.  **Не катастрофа:** Обнаружено мониторингом, влияло на производительность, а не на функциональность или данные. Не привело к сбою обновлений, только к задержкам.
3.  **Четкое описание:** Что было, почему случилось (ошибка в коде), как нашли (мониторинг, логи, pprof), как исправили (хотфикс + рефакторинг), какие уроки.
4.  **Акцент на решении и уроках:** Показан процесс отладки, инструменты (pprof), командная работа.
5.  **Демонстрация роста:** Извлек конкретные технические уроки.

**Ключевые моменты для обоих ответов:**

- **Используйте термины из истории:** Kafka, Redis, MQTT, Prometheus, gRPC, микросервисы, горутины, статусы, задания, roll-out, OTA, устройства (STM32/Jetson/ESP32), КАМАЗ.
- **Будьте скромны:** Вы были частью команды, работали под руководством. "Мы проанализировали", "TeamLead помог", "под руководством сеньора".
- **Фокус на процессе и решении:** Как вы _анализировали_, _диагностировали_, _исправляли_, _тестировали_, _предотвращали повторение_.
- **Покажите уроки:** Чему конкретно вы научились из этого опыта?
- **Связь с проектом:** Всегда привязывайте ответ к контексту OTA-обновлений для самосвалов и вашей конкретной роли в проекте.

================================

- **Главные уроки:**
  - **Блокировки и сеть не дружат:** Никогда не держи мьютекс во время сетевого IO или долгих операций.
  - **Знай свои инструменты:** Prometheus client сам обеспечивает потокобезопасность для `Inc()`, `Set()` – мой мьютекс был лишним. Всегда читай доки!
  - **Мониторинг – спасение:** Без алертов от Prometheus проблема бы затянулась.
  - **Профилирование (pprof) – must have:** Научился использовать его для диагностики блокировок.
  - **Командная работа и ревью:** Ошибку могли поймать на ревью, но еще важнее – как команда слаженно ее исправила.

**Итог проекта для меня:**
Это был мощный переход от Junior к уверенному Mid Go-разработчику. Я получил огромный опыт: Go (горутины, каналы, сети, БД, очереди), работу с Kafka, MQTT, Prometheus, PostgreSQL в контексте реальной промышленной IoT-системы. Главное – научился решать нетривиальные задачи в команде, анализировать ошибки и строить надежные системы. Понимаю ценность мониторинга, алертинга и командной работы в сложных проектах."

---

**Ключевые преимущества этого рассказа на собеседовании:**

1.  **Четкая структура:** Проект -> Моя роль (рост) -> Конкретная сложная задача (фокус на _вашей_ работе) -> Конкретный факап (фокус на _вашей_ ошибке и _командном_ решении) -> Итог роста.
2.  **Реалистичный уровень:** Вы – ценный командный игрок-исполнитель, выросший до мидла, а не архитектор-гений. Показано обучение у сеньоров.
3.  **Техническая глубина:** Использованы правильные термины (Kafka Consumer Groups, MQTT QoS, pprof, мьютексы, горутины, идемпотентность, Prometheus) – доказывает реальный опыт.
4.  **Фокус на решении проблем и уроках:** Показан процесс _анализа_ сложной задачи и _диагностики/исправления_ факапа. Акцент на _извлеченных уроках_ – это главное, что хочет услышать интервьюер.
5.  **Скромность и честность:** Признание ошибки (факап), благодарность команде/руководству.
6.  **Связь с бизнес-контекстом:** Понимание _почему_ проект важен (безопасные OTA для КАМАЗа в тяжелых условиях).
7.  **Уложено в 3-5 минут:** История сфокусирована, без воды.

**Дополнительные советы:**

- **Практика:** Отрепетируйте рассказ несколько раз вслух, уложившись в 4-5 минут. Засеките время.
- **Адаптация:** Будьте готовы чуть сократить или чуть расширить какую-то часть в зависимости от реакции интервьюера.
- **Искренность:** Рассказывайте уверенно, но без напора. Покажите вашу увлеченность техническими задачами и желание учиться.
- **Вопросы по проекту:** Будьте готовы ответить на уточняющие вопросы по любой части рассказа (про Kafka, MQTT, Go-конкурентность, Prometheus).

===========================================================

**MQTT (Message Queuing Telemetry Transport)** — это лёгкий сетевой протокол обмена сообщениями, специально разработанный для передачи данных в условиях:

- нестабильной или медленной связи,
- ограниченной полосы пропускания,
- устройств с низким энергопотреблением (например, IoT, микроконтроллеры).

---

## 🔧 Основные характеристики

| Особенность                      | Объяснение                                                                                                                                                      |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Модель pub/sub**               | Работает по модели публикация–подписка: отправитель (publisher) публикует сообщение в _тему_, а получатели (subscribers) получают всё, что приходит в эту тему. |
| **Брокер**                       | Центральный сервер (например, Mosquitto), который принимает сообщения и рассылает их подписчикам. Устройства не общаются напрямую.                              |
| **Маленький overhead**           | Очень компактный протокол — заголовок пакета от 2 байт.                                                                                                         |
| **QoS (качество доставки)**      | Поддерживает 3 уровня: "доставить 0 или 1 раз", "точно 1 раз", "не менее одного раза".                                                                          |
| **Поддержка offline**            | Сообщения могут храниться на брокере, пока подписчик не появится в сети.                                                                                        |
| **Сессии и удержание сообщений** | Поддерживает "чистые" и "сохраняемые" сессии, а также флаг `retain` (удержание последнего сообщения).                                                           |

---

## 📦 Где используется

- Умные дома (ESP32, Home Assistant)
- Телеметрия (включая автотранспорт, промышленность)
- OTA-обновления устройств
- Мобильные и низкоэнергетические приложения
- Сельское хозяйство, мониторинг климата, датчики и т.д.

---

## 🛠️ Пример простого взаимодействия

1. Устройство публикует:

   ```
   Тема: truck/123/status
   Сообщение: {"temp": 84.5, "rpm": 2500}
   ```

2. Сервер (или другое устройство), подписанный на `truck/+/status`, получает это сообщение и обрабатывает.

---

Хочешь — могу показать конкретный пример кода на Go или Python для MQTT, либо сравнить MQTT с HTTP/gRPC.

===============================================================
новые достижения и факапы

Сложная задача
Гарантированная доставка событий в Kafka без потерь при сбоях
Контекст:
Ты писал продюсер Kafka в Сервисе заданий: при создании или изменении задания нужно было отправить событие в Kafka (например, job.created, job.status.changed). Но был риск потери событий в случае сбоя между записью в PostgreSQL и отправкой в Kafka.

Проблема:

Если сначала сохранить в БД, потом отправить в Kafka — при краше после сохранения, но до отправки → событие теряется.

Если наоборот — сначала отправить в Kafka, потом в БД — тогда клиент Kafka может получить событие, а данных в БД ещё нет.

Что ты сделал:

Вместе с TeamLead реализовали "outbox pattern":

Сначала записывали событие в отдельную таблицу event_outbox внутри одной транзакции с заданием.

Отдельный воркер (goroutine) периодически читал event_outbox, публиковал событие в Kafka и помечал его как "отправлен".

Добавил retry-механику и дед-латтер логику (если событие не удается отправить N раз — уходит в отдельную таблицу event_dead_letter для расследования).

Метрики: outbox_pending_total, outbox_errors_total.

Результат:

Потери событий между БД и Kafka полностью исключены.

Сервис стал гораздо надежнее при перезапусках или кратковременных сбоях Kafka.

Зачем всё это?
Если бы ты сразу пытался отправить в Kafka (минуя event_outbox), то: - Kafka недоступна → событие потеряно. - Или: отправил в Kafka, а потом не смог записать в PostgreSQL → рассинхрон.

А с event_outbox у тебя есть: - атомарность — всё важное сохраняется в БД. - гарантия доставки — даже если Kafka лежит, событие не потеряно. - retry — временные сбои не страшны. - контроль — если что-то не отправляется долго, ты это знаешь.

Почему круто:
Паттерн "outbox" — очень уместен в реальных прод-системах.
Показано понимание проблемы атомарности между БД и брокером.
Имеется архитектурное мышление — даже если это было по совету тимлида.

================================
Факап (пример №3): Проблема с конкурентной модификацией заданий
Что произошло:

Устройства слали статусы одновременно (например, 30 устройств из одной группы).

В Event-сервисе шёл gRPC вызов в Job-сервис: обновить статус задания.

Ты не предусмотрел блокировку на уровне БД или optimistic locking.

В итоге:

При одновременном обновлении одного и того же задания, происходил race condition:

Один статус "затирал" другой (например, in_progress пришёл после done).

В БД оказывался некорректный финальный статус.

Как решили:

Вместе с более опытным коллегой внедрили optimistic locking:

В таблицу заданий добавили поле version INT.

Обновление шло с условием WHERE id = ? AND version = ?.

Если обновление не произошло (0 строк) — повторить попытку (до N раз).

Также валидацию: нельзя обновить done → in_progress.

Уроки:

Работа с конкурентными обновлениями — тонкая вещь.

Лучше превентивно закладываться на race conditions, особенно в системах с высоким параллелизмом.

В Go нет глобального mutex — нужно проектировать защиту на уровне БД.

==================================================================================
Вот тебе **шпаргалка перед интервью** по проекту с OTA-обновлениями для КАМАЗ, заточенная под позицию Go backend-разработчика уровня Middle. Она поможет быстро освежить ключевые моменты и уверенно отвечать на вопросы.

---

## 🔹 1. Кратко о проекте (Elevator pitch)

> Разрабатывали систему централизованных OTA-обновлений для бортовой электроники самосвалов КАМАЗ в условиях нестабильной связи. Обновления шли на STM32, Jetson, ESP32 через шлюз и управлялись из единого UI. Backend — на Go, микросервисная архитектура, Kafka, PostgreSQL, gRPC, MinIO, Prometheus. Я отвечал за несколько ключевых сервисов, начинал с CRUD и перешёл к задачам по асинхронной логике, Kafka, Roll-out и отказоустойчивости.

---

## 🔹 2. Архитектура — быстро и понятно

- **API Gateway** — точка входа (gRPC/REST).
- **Jobs Service** — хранение заданий, статусы, PostgreSQL.
- **Scheduler** — отслеживание времени запуска OTA.
- **Dispatcher** — выдаёт команды устройствам (MQTT).
- **Events Service** — слушает статусы от устройств (MQTT/Kafka), обновляет `job` и `job_devices`.
- **Roll-out Service** — стратегия массового обновления партиями.
- **MinIO** — хранилище прошивок.
- **Kafka / Redis** — шина между сервисами.
- **Prometheus / Grafana** — мониторинг, метрики.

**На КАМАЗе:**

- Jetson-шлюз: получает MQTT-команду → качает прошивку → обновляет STM32/ESP32 → шлёт статус.
- Устройство работает с `job_id` через шлюз.

---

## 🔹 3. Процесс обновления:

1.  Оператор создает задание в UI (устройство, версия прошивки, время запуска).
2.  `API Gateway` передает задание в `Сервис управления заданиями`.
3.  `Планировщик` видит задание с временем запуска. Когда время наступает, он помечает задание "готово к выполнению".
4.  `Диспетчер` находит готовые задания. Для каждого:
    - Формирует MQTT-команду на обновление для конкретного устройства/шлюза.
    - Отправляет команду через MQTT-брокер.
5.  Устройство/Шлюз получает команду:
    - Загружает указанную прошивку с MinIO.
    - Обновляет себя, проходя этапы (`init`, `downloading`, `flashing`, `rebooting`).
    - Отправляет статусы обратно через MQTT (`in_progress`, `downloading`, `done`, `error`).
6.  `Сервис обработки событий` подписан на MQTT/Kafka, получает статусы:
    - Обновляет статус задания и лог в `Сервисе управления заданиями` (PostgreSQL).
    - Отправляет метрики в Prometheus (через встроенный клиент).
    - Если реализован Roll-out, уведомляет `Сервис Roll-out` о статусе для управления очередностью партий.
7.  UI отображает актуальные статусы заданий и устройств.

---

## 🔹 4. Моя зона ответственности

- Job Service: CRUD, PostgreSQL, миграции (`golang-migrate`), gRPC.
- Event Service: Kafka-консьюмер, парсинг статусов, обновление `job`, Prometheus-метрики.
- Rollout: уведомления о завершении устройства в партии, учёт batch-групп.
- Интеграции: gRPC, Kafka (sarama), Redis (go-redis), Prometheus (client_golang).
- Работа с асинхронной логикой, каналами, горутинами, retry.

---

## 🔹 5. Мое конкретное участие и вклад (Junior -> Mid Go разработчик):

Я работал в команде бэкенд-разработчиков под руководством TeamLead и более опытных мидлов/сеньоров. Мои задачи и зона ответственности развивались по мере роста:

1.  **Разработка и поддержка Сервиса управления заданиями (начало, Junior):**

    - **Задачи:** Написание CRUD-операций для заданий в PostgreSQL (под руководством). Реализация простых эндпоинтов gRPC (GetJobByID, ListJobs) по готовым прото-контрактам.
    - **Технологии:** Go, PostgreSQL (драйвер `pgx`/`sqlx`), gRPC (`protobuf`, `grpc-go`).
    - **Уровень:** Исполнение четких ТЗ, код-ревью у сеньоров, изучение best practices.

2.  **Интеграция с очередью (Kafka/Redis) и Планировщиком (рост до Mid):**

    - **Задачи:**
      - Реализация продюсера в Сервисе заданий: При создании/изменении задания отправлять событие в Kafka/Redis (по готовой схеме события).
      - Реализация консьюмера в Планировщике: Чтение событий из Kafka/Redis, фильтрация событий о "готовности" задания, передача готовых заданий во внутреннюю очередь Планировщика (канал Go).
      - Помощь в поддержке логики Планировщика: Реализация worker'ов на горутинах, обрабатывающих задания из внутренней очереди и передающих их Диспетчеру (через вызов его API или общую шину).
    - **Технологии:** Go, Kafka (`sarama` клиент) / Redis (`go-redis`), горутины, каналы.
    - **Уровень:** Работа с асинхронными паттернами, понимание работы брокеров сообщений, решение задач средней сложности под умеренным контролем.

3.  **Работа с Диспетчером и MQTT:**

    - **Задачи:**
      - Интеграция Диспетчера с MQTT-брокером (например, EMQX): Настройка подключения, реализация публикации команд обновления в нужные MQTT-топики (`kamaz/vin123/update/command`) по шаблону от embedded-инженера.
      - Обработка ошибок отправки (таймауты, ошибки сети), реализация простого retry механизма (по ТЗ).
    - **Технологии:** Go, MQTT (клиент типа `paho.mqtt.golang`).
    - **Уровень:** Работа с внешними протоколами, реализация сетевой логики.

4.  **Сервис обработки событий (статусы) и Мониторинг:**

    - **Задачи:**
      - Реализация консьюмера MQTT/Kafka в Сервисе событий для приема статусов от устройств (`kamaz/+/update/status`).
      - Парсинг входящих статусов (JSON), валидация.
      - Обновление статуса соответствующего задания в Сервисе управления заданиями через его API.
      - Инструментирование кода: Добавление метрик Prometheus (счетчики `update_requests_total`, `update_errors_total` по типам ошибок, гистограммы `download_duration_seconds`) по согласованным метрикам от DevOps/TeamLead.
    - **Технологии:** Go, MQTT/Kafka, Prometheus client (`prometheus/client_golang`), gRPC (вызовы других сервисов).
    - **Уровень:** Интеграция между сервисами, работа с метриками, обработка событий в реальном времени.

5.  **Участие в реализации Roll-out (под руководством):**
    - **Задачи:** Не разрабатывал стратегию, но реализовывал ее часть по ТЗ:
      - В Сервисе заданий: Добавление поля `batch_group` к заданию при создании массового обновления.
      - В Сервисе событий: При получении статуса `done`/`error` от устройства, уведомление `Сервиса Roll-out` (через Kafka/API) о результате в конкретной `batch_group`.
      - В Сервисе Roll-out (помощь): Реализация логики ожидания успеха N% устройств в группе перед отправкой сигнала `Планировщику` на запуск следующей партии (через событие в Kafka/Redis).
    - **Уровень:** Работа над важным, но четко поставленным кусочком функционала в рамках общей стратегии.

**Что я освоил/укрепил:**

- **Go:** От базового синтаксиса до работы с горутинами, каналами, сетевыми запросами (gRPC, HTTP), БД (PostgreSQL), брокерами (Kafka, Redis, MQTT), метриками (Prometheus).
- **Архитектура:** Понимание микросервисной архитектуры, взаимодействие сервисов через gRPC и очереди (Kafka/Redis).
- **Базы данных:** Работа с PostgreSQL (структуры, запросы, миграции - возможно с инструментами вроде `golang-migrate`).
- **Инфраструктурные компоненты:** Практический опыт работы с Kafka, Redis, MQTT, MinIO, Docker.
- **Процессы:** Работа в команде, Git, CI/CD (наблюдение/использование), код-ревью, работа по ТЗ и спецификациям.

**Итог моего участия:**
Я был **исполнителем** в команде backend-разработчиков, ответственным за реализацию и поддержку **конкретных модулей и интеграций** в рамках общей архитектуры, спроектированной TeamLead и архитектором. Мои задачи были четко поставлены, а решения часто проходили ревью у более опытных коллег. Я начинал с простых CRUD и к концу проекта уверенно работал над задачами средней сложности, связанными с асинхронной обработкой событий, сетевым взаимодействием и интеграцией компонентов системы. Проект стал отличной школой для перехода от Junior к Mid-уровню в Go-разработке, дал глубокое понимание backend-разработки для IoT-систем в промышленном контексте.

---

## 🔹 6. Сложная задача

**Outbox pattern для Kafka**:

> Чтобы не терять события между БД и Kafka, мы внедрили outbox-паттерн: событие пишется в `event_outbox` в одной транзакции с заданием → воркер читает из таблицы → публикует в Kafka → помечает `sent` → в случае неудачи делает retry → если превышен лимит — отправляется в `event_dead_letter`. Это гарантирует доставку событий без потерь даже при сбоях.

---

## 🔹 7. Факап

**Конкурентное обновление `job.status` при массовых статусах `done`**:

> Несколько устройств одновременно слали статус `done`. Event-сервис через gRPC обновлял одну и ту же запись в `jobs`. Без контроля версий возникали гонки: один поток писал `done`, другой — `in_progress`. Статус “откатывался”. Решили через optimistic locking: добавили `version` в таблицу, обновляли с `WHERE version = ?`, при конфликте — повторная попытка. Это решило проблему.

---

## 🔹 8. Почему это крутой проект

- Работа с реальным железом, нестабильной связью, полевыми условиями.
- Много настоящей backend-инженерии: очередь, согласованность, отказоустойчивость.
- Микросервисная архитектура: gRPC + Kafka + Prometheus.
- Рост от Junior до уверенного Mid: сначала CRUD, потом сложная логика, потом архитектурные решения (outbox, concurrency).

---

## 🔹 9. Что я использовал и выучил

| Технология     | Что делал                                            |
| -------------- | ---------------------------------------------------- |
| **Go**         | goroutines, channels, sync, context, net/http, gRPC  |
| **PostgreSQL** | sqlx, pgx, транзакции, индексы, миграции (`migrate`) |
| **Kafka**      | sarama, producer/consumer, outbox pattern            |
| **gRPC**       | protobuf, unary, типы, backward-compatible изменения |
| **Redis**      | pub/sub, очереди, TTL                                |
| **Prometheus** | метрики, гистограммы, алерты                         |
| **Docker**     | сборка микросервисов, локальное окружение            |
| **CI/CD**      | lint, тесты, миграции при деплое (наблюдение)        |

---

## 🔹 10. Возможные вопросы на интервью (и как отвечать кратко)

| Вопрос                                  | Краткий ответ                                                                |
| --------------------------------------- | ---------------------------------------------------------------------------- |
| Как вы решали проблему согласованности? | Через optimistic locking и outbox pattern. Безопасные обновления и события.  |
| Как у вас был устроен Rollout?          | Партиями: отслеживали статус группы устройств, запускали следующую волну.    |
| Почему Kafka, а не RabbitMQ?            | Kafka лучше для долговременного хранения событий, масштабируемости и replay. |
| Как обрабатывались сбои?                | Retry, дед-леттеры, метрики + алерты через Prometheus.                       |
| Как вы тестировали?                     | Интеграционные тесты, нагрузочные тесты для Event-сервиса.                   |

---

вопросы от HR

парочка сопроводов

1. универсальное
2. более персональное

AGILE c контрольными точками (спринты + с синком раз в неделю)
Я вижу себя тимлидом через 3 года (не страшно в коммуникацию, люблю взаимодействовать с людьми)
интересоваться много ли проектов, допом иду или на замену кому то.
